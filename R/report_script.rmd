---
title: "Structural Equation Modeling"
author: "Julian Ibarguen"
date: "25/08/2022"
header-includes:
- \usepackage{booktabs}
- \usepackage{makecell}
- \usepackage{colortbl}
- \usepackage{wrapfig}
- \usepackage{subfig}
- \usepackage{lscape}
- \usepackage{natbib}
- \newcommand{\blandscape}{\begin{landscape}}
- \newcommand{\elandscape}{\end{landscape}}
output:
  pdf_document:
    toc: true
    toc_depth: 3
    number_sections: true
    fig_caption: true
    extra_dependencies: "subfig"
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE, warning = FALSE, message = FALSE)


format_tbl <- function(.data, caption = "Table") {
  
  align.c <- rep("c", ncol(.data) - 1)
  
  kableExtra::kbl(
    .data, format = "latex", booktabs = TRUE,
    align = c("l", align.c), digits = 3,
    caption = caption
  ) %>%
    kableExtra::kable_styling(latex_options = c("hold_position", "striped")) %>%
    kableExtra::row_spec(0, bold = TRUE) %>%
    kableExtra::column_spec(0, bold = TRUE)

}

```

## Introduction

We aim to fit a Structural Equation Model (SEM) following the exercise proposed by Petri Nokelainen from the Research Centre for Vocational Education, University of Tampere, Finland. Data and documentation for this exercise can be found [\textcolor{blue}{here}](https://www.scribd.com/document/222003310/Sem-Exercise-v2-5).

We used the proposed data set with `r nrow(df)` rows and `r ncol(df)` columns. The respondents in both samples are staff members of Finnish polytechnic institute for higher education. The original measurement instrument (Growth-oriented Atmosphere Questionnaire, GOAQ) has 13 factors and 92-items (Ruohotie, 1996; Ruohotie, Nokelainen & Tirri, 2002), but for the purposes of this exercise Nokelainen selected 13 factors and 27 items, all consisting of a five–point Likert scale from 1 (totally disagree) to 5 (totally agree) was applied (Nokelainen, n.d.)

## Evaluation of assumptions

### Univariate distribution

Although data is ordinal, thus non-normal in nature, we check for normality assumption. We will apply z re-scaling to see how they approximate to mean 0. Will also check kurtosis and skewnewss, and plot the histograms. We reject applying Saphiro test or other normality test, as being only 5 points scale ordinal is unlikely will provide any meaningful result.

Given a normally distribute variable would have a skewness of 0 and kurtosis of 3. For this purpose we calculated a synthetic measure for skewness and kurtosis as the average between the skewness and excess kurtosis ($kurtosis - 3$). Under this synthetic measure, a perfect normal distribution would have a value of 0. For our purpose, we select those variables whose deviance from the normal distribution is lower than 0.4, according to the synthetic measure create. The selected variables were further confirmed with the histogram.


Observing table 1 and figure 1, we assumed normality for the following variables: `r paste(norm_stats[norm_stats$avg_skew_kurt < 0.4, "variable"][[1]], collapse = ", ")`. The remaining variables were assumed non-normally distributed


```{r norm_descr}
format_tbl(norm_stats, "Descriptive statistics to assess approximation to normal distribution")
```


```{r histogram, fig.dim = c(11,15), fig.cap = "Histograms"}
p_hist
```

### Bivariate distribution

Based on the univariate analysis, we select three different variable combinations: 1) both are assumed normally distributed; 2) one is assumed normally distributed, but the other one no; 3) neither fo them is assumed normally distributed. 

In figure 2, we can observe the linear relationship between the 3 different combination. When we assume normality in both variables, we observe linear relationship, which decreases for the second combination (one variable assumed normal and the other no), and the relationship disappear for the third combination

```{r bivariates, fig.show = "hold", fig.ncol = 2, fig.align = 'center', out.width = "50%", fig.cap = "Bivariate distributions", fig.subcap = c("Two variables assumed normally distributed", "One variable assumed normally distributed", "No variable assumed normally distributed")}
p_norm2
p_norm1
p_norm0
```


### Correlation matrix

We observe now the correlation matrix between all `r ncol(df)` variables. For SEM and other factorial type of analysis, the correlation coefficient should be between $\pm 0.3$ and $\pm 0.8$. Too low correlations indicate weak inter-item dependency, too high correlations might indicate multicollinearity (Nokelainen, n.d.). 

The highest correlation coefficient ($r$) in absolute terms was betwee `r max_r_vars` with $r = $`r max_r` and $R^2$ = `r `max_r2`. The lowest correlation coefficient ($r$) was between `r min_r_vars` with $r = $`r min_r` and $R^2$ = `r `min_r2`. Therefore, we cna conlcude that our variables are suitable for a SEM model


```{r cor_plot, fig.dim = c(15, 15), fig.cap = "Correlation matrix"}
corrplot.mixed(
  cor(df, use = "complete.obs"), 
  lower = 'number', upper = 'square', 
  tl.cex = 1.25, number.cex = 1, number.digits = 2
)
```


## Path analysis

### Model 1

To perform the path analysis we make use of the 13 factors available in our data. The data consists of the thirteen growth-oriented atmosphere factors. The sample is the same as in data1, 447 staff members of Finnish polytechnic institute for higher education. The sample was collected in 2000.

Over this data we are interested on knwoing the determinant for _Valuation of the work_. We fit the following model:

$$ta\_val7 = \beta_0 + \beta_1 kj\_enc1 + \beta_2 op\_rew3 + \beta_3 tk\_inv5 + \beta_4ts\_cla + \varepsilon_{ta\_val7}$$

where:

```{r var_names}
var_dict <- as_tibble(as.list(var_labs)) %>% 
  tidyr::pivot_longer(1:length(var_labs), names_to = "variable_name", values_to = "variable_label")

# var_dict[var_dict$variable_name %in% names(p_path$Arguments$labels) , "model_acronym"] <- p_path$Arguments$labels
# var_dict[is.na(var_dict$model_acronym),"model_acronym"] <- ""

var_dict <- dplyr::relocate(var_dict, variable_label, .before = 1)

format_tbl(var_dict, "Labels for factor variables")

```

The summary of the model was the following:

```{r summary_fit}
fit_summary

```

```{r calculate}
r2 <- fit_pe[which(fit_pe$op == "r2"), "est"]

fit_pe_reg <- dplyr::arrange(tidy_fit[tidy_fit$op == "~", ], dplyr::desc(est_std))

```
```{r path_plot, out.width = "60%", fig.cap = "Fitted model", fig.align = 'center'}
p_path
```

From the results of the model we obtain the following conclusions:

* How much dependent variable variance the four independent variables predict? $R^2 = `r round(r2,3)`$ .

* Order the IVs in the following rows (best predictor comes first):
  1. The first (strongest) predictor for Valuation of the work is _`r var_labs[names(var_labs) %in% fit_pe_reg[1, "rhs"]]`_ $r = `r fit_pe_reg[1, "est_std"]`$
  2. The second predictor for Valuation of the work is _`r var_labs[names(var_labs) %in% fit_pe_reg[2, "rhs"]]`_ $r = `r fit_pe_reg[2, "est_std"]`$
  3. The third predictor for Valuation of the work is _`r var_labs[names(var_labs) %in% fit_pe_reg[3, "rhs"]]`_ $r = `r fit_pe_reg[3, "est_std"]`$
  4. The fourth predictor for Valuation of the work is _`r var_labs[names(var_labs) %in% fit_pe_reg[4, "rhs"]]`_ $r = `r fit_pe_reg[4, "est_std"]`$

* Select Unstandardized estimates and complete the following sentences:
  * When _Encouraging leadership_ goes up by 1, _Valuation of the work_ goes up by `r fit_pe_reg[fit_pe_reg$from == "kj_enc1", "est"]`.
  * When _Know-how rewarding_ goes up by 1, _Valuation of the work_ goes up `r fit_pe_reg[fit_pe_reg$from == "op_rew3", "est"]`.


### Model 2

We modify the model 1 to account for an indirect effect from _Know-how rewarding_ (op_rew3) via _Incentive value of of the work_ (tk_inv5) to _Valuation of the work_ (ta_val7).

$$ta\_val7 = \beta_0 + \beta_1 kj\_enc1 + \beta_2 op\_rew3 + \beta_3ts\_cla + \beta_4 op\_rew3 * tk_inv5 + \varepsilon_{ta\_val7}$$

By accounting for the mediation effect, we obtain the following result:

```{r summary_med}
fit_summary_med 

```
```{r path_plot_med, out.width = "60%", fig.cap = "Fitted model with mediation", fig.align = 'center'}
p_path_med
```

And we can extract the following conclusions:

```{r calculate_med}
r2_med <- fit_pe_med[which(fit_pe_med$op == "r2"), "est"]

fit_pe_reg_med <- dplyr::arrange(tidy_fit[tidy_fit$op == "~", ], dplyr::desc(est_std))

```


* How much DV‟s variance the four IV‟s predict? Model 1 $R^2 = `r round(r2,3)`$. Compared to Model 2 with mediation `r round(sum(r2_med),3)` %.
* How does the indirect path affect the regression model? controlling for the mediation effect have improved the effect of Clarity of the work (ts_cla6) and _Know-how rewarding_ (op_rew3). On the contrary have decreased the effect of _Encouraging leadership_ (kj_enc1). However, the new model seems to explain better the _Valuation of the work_ (ta_val7),a s per $R2$ metric.



## Latent variable model

The model examines how encouraging leadership and build-up of work requirements together affect on psychical stress of the work






























